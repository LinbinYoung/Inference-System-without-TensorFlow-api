{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One basic Mnist TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = 'new_ckpt_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.001\n",
    "        self.global_step = tf.Variable(0,trainable = False)\n",
    "        self.x = tf.placeholder(tf.float32,[None,784], name = 'x_input')\n",
    "        self.label = tf.placeholder(tf.float32,[None,10], name = 'y_input')\n",
    "        self.w = tf.Variable(tf.zeros([784,10]))\n",
    "        self.b = tf.Variable(tf.zeros([10]))\n",
    "        self.y = tf.nn.softmax(tf.matmul(self.x,self.w) + self.b, name = 'z_output')\n",
    "        self.loss = -tf.reduce_mean(self.label * tf.log(self.y) + 1e-10)\n",
    "        self.train = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.loss,global_step = self.global_step)\n",
    "        predict = tf.equal(tf.argmax(self.label,1),tf.argmax(self.y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(predict,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.net = Network()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.data = input_data.read_data_sets('./dataset',one_hot = True)\n",
    "\n",
    "    def train(self):\n",
    "        batch_size = 64\n",
    "        train_step = 10000\n",
    "        step = 0\n",
    "        saver = tf.train.Saver(max_to_keep = 0)\n",
    "        ckpt = tf.train.get_checkpoint_state(CKPT_DIR)\n",
    "        if ckpt and ckpt.get_checkpoint_state(CKPT_DIR):\n",
    "            saver.restore(self.sess,ckpt.model_checkpoint_path)\n",
    "            step = self.sess.run(self.net.global_step) #Fetch the global step from the CKPT model\n",
    "            print('continue from')\n",
    "            print('  -> Minibatch update : ',step)\n",
    "        while step < train_step:\n",
    "            x,label = self.data.train.next_batch(batch_size)\n",
    "            _,loss = self.sess.run([self.net.train,self.net.loss], feed_dict = {self.net.x: x,self.net.label:label})\n",
    "            step = self.sess.run(self.net.global_step)\n",
    "            if step % 1000 == 0:\n",
    "                print('No %6d step, current loss: %.3f'%(step,loss))\n",
    "            if step % 10000 == 0:\n",
    "                saver.save(self.sess,CKPT_DIR + '/model',global_step = step)\n",
    "    \n",
    "    def calculate_accuracy(self):\n",
    "        test_x = self.data.test.images\n",
    "        test_label = self.data.test.labels\n",
    "        acc = self.sess.run(self.net.accuracy,feed_dict = {self.net.x:test_x,self.net.label:test_label})\n",
    "        print(\"acc: %.3f, Number of pic test: %d \" % (acc, len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4236aea9f80d>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./dataset/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./dataset/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./dataset/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./dataset/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "No   1000 step, current loss: 0.220\n",
      "No   2000 step, current loss: 0.210\n",
      "No   3000 step, current loss: 0.207\n",
      "No   4000 step, current loss: 0.191\n",
      "No   5000 step, current loss: 0.187\n",
      "No   6000 step, current loss: 0.181\n",
      "No   7000 step, current loss: 0.174\n",
      "No   8000 step, current loss: 0.165\n",
      "No   9000 step, current loss: 0.154\n",
      "No  10000 step, current loss: 0.154\n",
      "acc: 0.790, Number of pic test: 10000 \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = Train()\n",
    "    model.train()\n",
    "    model.calculate_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to reload model from the saved CPKT files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tensorboard to visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_structure = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "wirter = tf.summary.FileWriter('logs/',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $ tensorboard --logdir='/home/linbin/Tensorflow_Inference_C/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we could use tensorboard to see the net structure from our web broswer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to reload CKPT Model from local and do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_filenames(model_dir, model_exp):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise load_modelValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    #fetch the goal meta file\n",
    "    goal_meta_file = meta_files[0]\n",
    "    for each_file in meta_files:\n",
    "        if each_file.startswith(model_exp):\n",
    "            goal_meta_file = each_file\n",
    "            break\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)     # 通过checkpoint文件找到模型文件名\n",
    "    print (ckpt.model_checkpoint_path)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        # ckpt.model_checkpoint_path表示模型存储的位置，不需要提供模型的名字，它回去查看checkpoint文件\n",
    "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        return goal_meta_file, ckpt_file\n",
    "    \n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return goal_meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./new_ckpt_dir/model-10000\n"
     ]
    }
   ],
   "source": [
    "meta_file, ckpt_file = get_model_filenames(model_dir, model_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metagraph file: model-10000.meta\n",
      "Checkpoint file: model-10000\n"
     ]
    }
   ],
   "source": [
    "print ('Metagraph file: %s' % meta_file)\n",
    "print ('Checkpoint file: %s' % ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import pywrap_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tensor_name: ', 'Variable')\n",
      "('tensor_name: ', 'Variable_2')\n",
      "('tensor_name: ', 'Variable_1')\n"
     ]
    }
   ],
   "source": [
    "reader = pywrap_tensorflow.NewCheckpointReader(os.path.join(model_dir, ckpt_file))\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "for key in var_to_shape_map:\n",
    "    print(\"tensor_name: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the tensor W in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./new_ckpt_dir/model-10000\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_dir, meta_file))\n",
    "    saver.restore(tf.get_default_session(), os.path.join(model_dir, ckpt_file))\n",
    "    print (type(sess.run(tf.get_default_graph().get_tensor_by_name(\"Variable_1:0\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
