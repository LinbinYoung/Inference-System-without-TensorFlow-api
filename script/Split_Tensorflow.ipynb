{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore graph from ckpt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Graph using topo algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = ['x_input', 'y_input']\n",
    "output_tensor = 'z_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "node_dict = {}\n",
    "topo_map = {}\n",
    "node_order_list = []\n",
    "topo_map = collections.OrderedDict()\n",
    "node_dict=collections.OrderedDict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./new_ckpt_dir_4/model-2000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./new_ckpt_dir_3/model-10000.meta')\n",
    "    new_saver.restore(sess, './new_ckpt_dir_3/model-10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    for n in sess.graph_def.node:\n",
    "        node_dict[n.name] = n\n",
    "        node_order_list.append(n.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_order_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"rnn/strided_slice_1\"\n",
      "op: \"StridedSlice\"\n",
      "input: \"rnn/Shape_1\"\n",
      "input: \"rnn/strided_slice_1/stack\"\n",
      "input: \"rnn/strided_slice_1/stack_1\"\n",
      "input: \"rnn/strided_slice_1/stack_2\"\n",
      "attr {\n",
      "  key: \"Index\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"begin_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"ellipsis_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"end_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"new_axis_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shrink_axis_mask\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (node_dict['rnn/strided_slice_1']) # Last Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define muti-tree data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    __children = []\n",
    "    __tensor = None\n",
    "    __shape = None\n",
    "    \n",
    "    def __init__(self, name = None, child_list = [], parent = None, Op = None):\n",
    "        self.Op = Op\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        for elem in child_list:\n",
    "            self.__children.append(elem)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_child(self):\n",
    "        return self.__children\n",
    "    \n",
    "    def get_Op(self):\n",
    "        return self.Op\n",
    "    \n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def get_tensor(self):\n",
    "        return self.__tensor\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return self.__shape\n",
    "    \n",
    "    def set_shape(self, shape):\n",
    "        self.__shape = shape \n",
    "    \n",
    "    def set_tensor(self, tensor):\n",
    "        self.__tensor = tensor\n",
    "    \n",
    "    def set_parent(self, parent):\n",
    "        self.parent = parent\n",
    "    \n",
    "    def set_Op(self, Op):\n",
    "        self.Op = Op\n",
    "        \n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def set_child(self, chil):\n",
    "        self.__children = []\n",
    "        if chil == None:\n",
    "            return\n",
    "        for elem in chil:\n",
    "            self.__children.append(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Store all necessary node in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct child node list\n",
    "def Construct_Node_List(name_list, parent, node_dict):\n",
    "    # name_list: node_name of each graph node\n",
    "    # node_dict: key:node name; value: Node object\n",
    "    chil = []\n",
    "    if len(name_list) == 0 or (parent != None and parent.get_name().startswith('Variable') and parent.get_name().endswith('read')):\n",
    "        return None\n",
    "    else:\n",
    "        for elem in name_list:\n",
    "            print (elem)\n",
    "            chil.append(Node(elem, [], parent, node_dict[elem].op))\n",
    "    return chil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n"
     ]
    }
   ],
   "source": [
    "root = Node(output_tensor, Construct_Node_List(node_dict[output_tensor].input, None, node_dict), None, node_dict[output_tensor].op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n"
     ]
    }
   ],
   "source": [
    "print (root.get_child()[0].get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"rnn/while/Enter_2\"\n",
      "op: \"Enter\"\n",
      "input: \"rnn/TensorArray:1\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"frame_name\"\n",
      "  value {\n",
      "    s: \"rnn/while/while_context\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_constant\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"parallel_iterations\"\n",
      "  value {\n",
      "    i: 32\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (node_dict['rnn/while/Enter_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Construct Multi Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "---------------\n",
      "z_output\n",
      "***************\n",
      "add\n",
      "***************\n",
      "---------------\n",
      "add\n",
      "***************\n",
      "MatMul\n",
      "biases/b/read\n",
      "***************\n",
      "---------------\n",
      "MatMul\n",
      "***************\n",
      "strided_slice\n",
      "weights/W/read\n",
      "***************\n",
      "---------------\n",
      "biases/b/read\n",
      "***************\n",
      "biases/b\n",
      "***************\n",
      "---------------\n",
      "strided_slice\n",
      "***************\n",
      "rnn/transpose_1\n",
      "strided_slice/stack\n",
      "strided_slice/stack_1\n",
      "strided_slice/stack_2\n",
      "***************\n",
      "---------------\n",
      "weights/W/read\n",
      "***************\n",
      "weights/W\n",
      "***************\n",
      "---------------\n",
      "biases/b\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/transpose_1\n",
      "***************\n",
      "rnn/TensorArrayStack/TensorArrayGatherV3\n",
      "rnn/concat_2\n",
      "***************\n",
      "---------------\n",
      "strided_slice/stack\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "strided_slice/stack_1\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "strided_slice/stack_2\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "weights/W\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArrayStack/TensorArrayGatherV3\n",
      "***************\n",
      "rnn/TensorArray\n",
      "rnn/TensorArrayStack/range\n",
      "rnn/while/Exit_2\n",
      "***************\n",
      "---------------\n",
      "rnn/concat_2\n",
      "***************\n",
      "rnn/concat_2/values_0\n",
      "rnn/range_1\n",
      "rnn/concat_2/axis\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArray\n",
      "***************\n",
      "rnn/strided_slice_1\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArrayStack/range\n",
      "***************\n",
      "rnn/TensorArrayStack/range/start\n",
      "rnn/TensorArrayStack/TensorArraySizeV3\n",
      "rnn/TensorArrayStack/range/delta\n",
      "***************\n",
      "---------------\n",
      "rnn/while/Exit_2\n",
      "***************\n",
      "rnn/while/Switch_2\n",
      "***************\n",
      "---------------\n",
      "rnn/concat_2/values_0\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/range_1\n",
      "***************\n",
      "rnn/range_1/start\n",
      "rnn/Rank_1\n",
      "rnn/range_1/delta\n",
      "***************\n",
      "---------------\n",
      "rnn/concat_2/axis\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/strided_slice_1\n",
      "***************\n",
      "rnn/Shape_1\n",
      "rnn/strided_slice_1/stack\n",
      "rnn/strided_slice_1/stack_1\n",
      "rnn/strided_slice_1/stack_2\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArrayStack/range/start\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArrayStack/TensorArraySizeV3\n",
      "***************\n",
      "rnn/TensorArray\n",
      "rnn/while/Exit_2\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArrayStack/range/delta\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/while/Switch_2\n",
      "***************\n",
      "rnn/while/Merge_2\n",
      "rnn/while/LoopCond\n",
      "***************\n",
      "---------------\n",
      "rnn/range_1/start\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/Rank_1\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/range_1/delta\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/Shape_1\n",
      "***************\n",
      "rnn/transpose\n",
      "***************\n",
      "---------------\n",
      "rnn/strided_slice_1/stack\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/strided_slice_1/stack_1\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/strided_slice_1/stack_2\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "rnn/TensorArray\n",
      "***************\n",
      "rnn/strided_slice_1\n",
      "***************\n",
      "---------------\n",
      "rnn/while/Exit_2\n",
      "***************\n",
      "rnn/while/Switch_2\n",
      "***************\n",
      "---------------\n",
      "rnn/while/Merge_2\n",
      "***************\n",
      "rnn/while/Enter_2\n",
      "rnn/while/NextIteration_2\n",
      "***************\n",
      "---------------\n",
      "rnn/while/LoopCond\n",
      "***************\n",
      "rnn/while/LogicalAnd\n",
      "***************\n",
      "---------------\n",
      "rnn/transpose\n",
      "***************\n",
      "Reshape\n",
      "rnn/concat\n",
      "***************\n",
      "---------------\n",
      "rnn/strided_slice_1\n",
      "***************\n",
      "rnn/Shape_1\n",
      "rnn/strided_slice_1/stack\n",
      "rnn/strided_slice_1/stack_1\n",
      "rnn/strided_slice_1/stack_2\n",
      "***************\n",
      "---------------\n",
      "rnn/while/Switch_2\n",
      "***************\n",
      "rnn/while/Merge_2\n",
      "rnn/while/LoopCond\n",
      "***************\n",
      "---------------\n",
      "rnn/while/Enter_2\n",
      "***************\n",
      "rnn/TensorArray:1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rnn/TensorArray:1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ca886e35c5e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# update child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'***************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtemp_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstruct_Node_List\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'***************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# update queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-61458b864fa4>\u001b[0m in \u001b[0;36mConstruct_Node_List\u001b[0;34m(name_list, parent, node_dict)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mchil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rnn/TensorArray:1'"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "Q_1 = queue.Queue()\n",
    "Q_1.put(root)\n",
    "print(Q_1.qsize())\n",
    "while (Q_1.qsize() != 0):\n",
    "    temp_node = Q_1.get()\n",
    "    print ('---------------')\n",
    "    print (temp_node.get_name())\n",
    "    # update child\n",
    "    print ('***************')\n",
    "    temp_node.set_child(Construct_Node_List(node_dict[temp_node.get_name()].input, temp_node, node_dict))\n",
    "    print ('***************')\n",
    "    # update queue\n",
    "    for elem in temp_node.get_child():\n",
    "        Q_1.put(elem)\n",
    "# root.get_child()[0].get_child()[0].get_Op()\n",
    "def Loop_Multi_Tree(root):\n",
    "    if (len(root.get_child()) == 0):\n",
    "        # which means that it is one leaf node\n",
    "        indegree_node[root] = 0\n",
    "        return\n",
    "    indegree_node[root] = len(root.get_child())\n",
    "    for each_child_node in root.get_child():\n",
    "        print (each_child_node.get_name())\n",
    "        Loop_Multi_Tree(each_child_node)\n",
    "indegree_node = {}\n",
    "Loop_Multi_Tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate the degree of all nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Topo Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_topo = queue.Queue()\n",
    "for each_node in indegree_node:\n",
    "    if indegree_node[each_node] == 0:\n",
    "        q_topo.put(each_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print (q_topo.qsize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construct_topo_json(q_topo, graph, index, data, sess):\n",
    "    while (q_topo.qsize() != 0):\n",
    "        cur_size = q_topo.qsize()\n",
    "        step = \"step\" + str(index)\n",
    "        unit = {}\n",
    "        while cur_size > 0:\n",
    "            single_op = {}\n",
    "            temp_node = q_topo.get()\n",
    "            tensor = graph.get_tensor_by_name(temp_node.get_name()+\":\"+'0')\n",
    "            if temp_node.get_parent() != None:\n",
    "                indegree_node[temp_node.get_parent()] = indegree_node[temp_node.get_parent()] - 1\n",
    "                if (indegree_node[temp_node.get_parent()] == 0):\n",
    "                    q_topo.put(temp_node.get_parent())\n",
    "            if temp_node.get_name().startswith('Variable') and temp_node.get_Op() == 'Identity':\n",
    "                print ('We should get the actual tensor value of the node *** %s ***' % temp_node.get_name())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                tensor_value = tensor.eval(session=sess)\n",
    "                if type(tensor_value) != np.ndarray:\n",
    "                    tensor_value = np.array(tensor_value)\n",
    "                single_op[\"TENSOR_VALUE\"] = tensor_value.tolist()\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape)\n",
    "                single_op[\"STRIDE\"] = None\n",
    "                single_op[\"PADIING\"] = None\n",
    "                single_op[\"INPUT\"] = []\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            elif temp_node.get_Op() == 'Placeholder':\n",
    "                print ('We should fullfill the tensor *** %s *** with input value' % temp_node.get_name())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                single_op[\"TENSOR_VALUE\"] = None\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape)\n",
    "                single_op[\"STRIDE\"] = None\n",
    "                single_op[\"PADIING\"] = None\n",
    "                single_op[\"INPUT\"] = []\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            elif len(temp_node.get_child()) > 0:\n",
    "                # We should note the actual operations\n",
    "                print ('Do %s operation' % temp_node.get_Op())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                single_op[\"TENSOR_VALUE\"] = None\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape) if temp_node.get_Op() == 'Reshape' or temp_node.get_Op() == 'Conv2D' else None\n",
    "                if (temp_node.get_Op() == 'Conv2D'):\n",
    "                    single_op[\"STRIDE\"] = str(tuple([int(elem) for elem in node_dict[temp_node.get_name()].attr['strides'].list.i]))\n",
    "                    single_op[\"PADIING\"] = bytes.decode(node_dict[temp_node.get_name()].attr['padding'].s)\n",
    "                else:\n",
    "                    single_op[\"STRIDE\"] = None\n",
    "                    single_op[\"PADIING\"] = None\n",
    "                input_list = []\n",
    "                for each_input_node in temp_node.get_child():\n",
    "                    print(\"My name is *** %s *** and I am the input of *** %s ***\" % (each_input_node.get_name(), each_input_node.get_parent().get_name()))\n",
    "                    input_list.append(each_input_node.get_name())\n",
    "                single_op[\"INPUT\"] = input_list\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            else:\n",
    "                print ('Do %s operation' % temp_node.get_Op())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                single_op[\"TENSOR_VALUE\"] = None\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape)\n",
    "                single_op[\"STRIDE\"] = None\n",
    "                single_op[\"PADIING\"] = None\n",
    "                single_op[\"INPUT\"] = []\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            unit[temp_node.get_name()] = single_op\n",
    "            cur_size = cur_size - 1\n",
    "        index = index + 1\n",
    "        data[step] = unit\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./new_ckpt_dir_3/model-10000\n",
      "We should fullfill the tensor *** x_input *** with input value\n",
      "We should get the actual tensor value of the node *** Variable_1/read ***\n",
      "We should get the actual tensor value of the node *** Variable_2/read ***\n",
      "We should get the actual tensor value of the node *** Variable_3/read ***\n",
      "We should get the actual tensor value of the node *** Variable_4/read ***\n",
      "We should get the actual tensor value of the node *** Variable_5/read ***\n",
      "We should get the actual tensor value of the node *** Variable_6/read ***\n",
      "Do Const operation\n",
      "We should get the actual tensor value of the node *** Variable_7/read ***\n",
      "We should get the actual tensor value of the node *** Variable_8/read ***\n",
      "We should get the actual tensor value of the node *** Variable_9/read ***\n",
      "We should get the actual tensor value of the node *** Variable_10/read ***\n",
      "Do Conv2D operation\n",
      "My name is *** x_input *** and I am the input of *** Conv2D ***\n",
      "My name is *** Variable_1/read *** and I am the input of *** Conv2D ***\n",
      "Do Add operation\n",
      "My name is *** Conv2D *** and I am the input of *** add ***\n",
      "My name is *** Variable_2/read *** and I am the input of *** add ***\n",
      "Do Relu operation\n",
      "My name is *** add *** and I am the input of *** Relu ***\n",
      "Do Conv2D operation\n",
      "My name is *** Relu *** and I am the input of *** Conv2D_1 ***\n",
      "My name is *** Variable_3/read *** and I am the input of *** Conv2D_1 ***\n",
      "Do Add operation\n",
      "My name is *** Conv2D_1 *** and I am the input of *** add_1 ***\n",
      "My name is *** Variable_4/read *** and I am the input of *** add_1 ***\n",
      "Do Relu operation\n",
      "My name is *** add_1 *** and I am the input of *** Relu_1 ***\n",
      "Do Conv2D operation\n",
      "My name is *** Relu_1 *** and I am the input of *** Conv2D_2 ***\n",
      "My name is *** Variable_5/read *** and I am the input of *** Conv2D_2 ***\n",
      "Do Add operation\n",
      "My name is *** Conv2D_2 *** and I am the input of *** add_2 ***\n",
      "My name is *** Variable_6/read *** and I am the input of *** add_2 ***\n",
      "Do Relu operation\n",
      "My name is *** add_2 *** and I am the input of *** Relu_2 ***\n",
      "Do Reshape operation\n",
      "My name is *** Relu_2 *** and I am the input of *** Reshape ***\n",
      "My name is *** Reshape/shape *** and I am the input of *** Reshape ***\n",
      "Do MatMul operation\n",
      "My name is *** Reshape *** and I am the input of *** MatMul ***\n",
      "My name is *** Variable_7/read *** and I am the input of *** MatMul ***\n",
      "Do Add operation\n",
      "My name is *** MatMul *** and I am the input of *** add_3 ***\n",
      "My name is *** Variable_8/read *** and I am the input of *** add_3 ***\n",
      "Do Relu operation\n",
      "My name is *** add_3 *** and I am the input of *** Relu_3 ***\n",
      "Do MatMul operation\n",
      "My name is *** Relu_3 *** and I am the input of *** MatMul_1 ***\n",
      "My name is *** Variable_9/read *** and I am the input of *** MatMul_1 ***\n",
      "Do Add operation\n",
      "My name is *** MatMul_1 *** and I am the input of *** add_4 ***\n",
      "My name is *** Variable_10/read *** and I am the input of *** add_4 ***\n",
      "Do Softmax operation\n",
      "My name is *** add_4 *** and I am the input of *** z_output ***\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./new_ckpt_dir_3/model-10000.meta')\n",
    "    new_saver.restore(sess, './new_ckpt_dir_3/model-10000')\n",
    "    graph = tf.get_default_graph()\n",
    "    from collections import OrderedDict\n",
    "    data = OrderedDict()\n",
    "    index = 0\n",
    "    data = Construct_topo_json(q_topo, graph, index, data, sess)\n",
    "    with open (\"model6.json\", \"w\") as fp:\n",
    "        fp.write(json.dumps(data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
