{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore graph from ckpt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Graph using topo algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = ['x_input', 'y_input']\n",
    "output_tensor = 'z_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "node_dict = {}\n",
    "topo_map = {}\n",
    "node_order_list = []\n",
    "topo_map = collections.OrderedDict()\n",
    "node_dict=collections.OrderedDict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/linbinyang/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./new_ckpt_dir_3/model-10000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./new_ckpt_dir_3/model-10000.meta')\n",
    "    new_saver.restore(sess, './new_ckpt_dir_3/model-10000')\n",
    "#     graph = tf.get_default_graph()\n",
    "#     tensor = graph.get_tensor_by_name('Variable_87/read:0')\n",
    "#     tensor_value = tensor.eval(session=sess)\n",
    "#     print ([int(elem) for elem in tensor.shape])\n",
    "#     print (type(tensor_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    for n in sess.graph_def.node:\n",
    "        node_dict[n.name] = n\n",
    "        node_order_list.append(n.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_order_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"x_input\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 28\n",
      "      }\n",
      "      dim {\n",
      "        size: 28\n",
      "      }\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (node_dict['x_input']) # Last Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define muti-tree data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    __children = []\n",
    "    __tensor = None\n",
    "    __shape = None\n",
    "    \n",
    "    def __init__(self, name = None, child_list = [], parent = None, Op = None):\n",
    "        self.Op = Op\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        for elem in child_list:\n",
    "            self.__children.append(elem)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_child(self):\n",
    "        return self.__children\n",
    "    \n",
    "    def get_Op(self):\n",
    "        return self.Op\n",
    "    \n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "    \n",
    "    def get_tensor(self):\n",
    "        return self.__tensor\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return self.__shape\n",
    "    \n",
    "    def set_shape(self, shape):\n",
    "        self.__shape = shape \n",
    "    \n",
    "    def set_tensor(self, tensor):\n",
    "        self.__tensor = tensor\n",
    "    \n",
    "    def set_parent(self, parent):\n",
    "        self.parent = parent\n",
    "    \n",
    "    def set_Op(self, Op):\n",
    "        self.Op = Op\n",
    "        \n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def set_child(self, chil):\n",
    "        self.__children = []\n",
    "        if chil == None:\n",
    "            return\n",
    "        for elem in chil:\n",
    "            self.__children.append(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Store all necessary node in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct child node list\n",
    "def Construct_Node_List(name_list, parent, node_dict):\n",
    "    # name_list: node_name of each graph node\n",
    "    # node_dict: key:node name; value: Node object\n",
    "    chil = []\n",
    "    if len(name_list) == 0 or (parent != None and parent.get_name().startswith('Variable') and parent.get_name().endswith('read')):\n",
    "        return None\n",
    "    else:\n",
    "        for elem in name_list:\n",
    "            print (elem)\n",
    "            chil.append(Node(elem, [], parent, node_dict[elem].op))\n",
    "    return chil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_4\n"
     ]
    }
   ],
   "source": [
    "root = Node(output_tensor, Construct_Node_List(node_dict[output_tensor].input, None, node_dict), None, node_dict[output_tensor].op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_4\n"
     ]
    }
   ],
   "source": [
    "print (root.get_child()[0].get_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Construct Multi Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "---------------\n",
      "z_output\n",
      "***************\n",
      "add_4\n",
      "***************\n",
      "---------------\n",
      "add_4\n",
      "***************\n",
      "MatMul_1\n",
      "Variable_10/read\n",
      "***************\n",
      "---------------\n",
      "MatMul_1\n",
      "***************\n",
      "Relu_3\n",
      "Variable_9/read\n",
      "***************\n",
      "---------------\n",
      "Variable_10/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "Relu_3\n",
      "***************\n",
      "add_3\n",
      "***************\n",
      "---------------\n",
      "Variable_9/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "add_3\n",
      "***************\n",
      "MatMul\n",
      "Variable_8/read\n",
      "***************\n",
      "---------------\n",
      "MatMul\n",
      "***************\n",
      "Reshape\n",
      "Variable_7/read\n",
      "***************\n",
      "---------------\n",
      "Variable_8/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "Reshape\n",
      "***************\n",
      "Relu_2\n",
      "Reshape/shape\n",
      "***************\n",
      "---------------\n",
      "Variable_7/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "Relu_2\n",
      "***************\n",
      "add_2\n",
      "***************\n",
      "---------------\n",
      "Reshape/shape\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "add_2\n",
      "***************\n",
      "Conv2D_2\n",
      "Variable_6/read\n",
      "***************\n",
      "---------------\n",
      "Conv2D_2\n",
      "***************\n",
      "Relu_1\n",
      "Variable_5/read\n",
      "***************\n",
      "---------------\n",
      "Variable_6/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "Relu_1\n",
      "***************\n",
      "add_1\n",
      "***************\n",
      "---------------\n",
      "Variable_5/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "add_1\n",
      "***************\n",
      "Conv2D_1\n",
      "Variable_4/read\n",
      "***************\n",
      "---------------\n",
      "Conv2D_1\n",
      "***************\n",
      "Relu\n",
      "Variable_3/read\n",
      "***************\n",
      "---------------\n",
      "Variable_4/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "Relu\n",
      "***************\n",
      "add\n",
      "***************\n",
      "---------------\n",
      "Variable_3/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "add\n",
      "***************\n",
      "Conv2D\n",
      "Variable_2/read\n",
      "***************\n",
      "---------------\n",
      "Conv2D\n",
      "***************\n",
      "x_input\n",
      "Variable_1/read\n",
      "***************\n",
      "---------------\n",
      "Variable_2/read\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "x_input\n",
      "***************\n",
      "***************\n",
      "---------------\n",
      "Variable_1/read\n",
      "***************\n",
      "***************\n",
      "add_4\n",
      "MatMul_1\n",
      "Relu_3\n",
      "add_3\n",
      "MatMul\n",
      "Reshape\n",
      "Relu_2\n",
      "add_2\n",
      "Conv2D_2\n",
      "Relu_1\n",
      "add_1\n",
      "Conv2D_1\n",
      "Relu\n",
      "add\n",
      "Conv2D\n",
      "x_input\n",
      "Variable_1/read\n",
      "Variable_2/read\n",
      "Variable_3/read\n",
      "Variable_4/read\n",
      "Variable_5/read\n",
      "Variable_6/read\n",
      "Reshape/shape\n",
      "Variable_7/read\n",
      "Variable_8/read\n",
      "Variable_9/read\n",
      "Variable_10/read\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "Q_1 = queue.Queue()\n",
    "Q_1.put(root)\n",
    "print(Q_1.qsize())\n",
    "while (Q_1.qsize() != 0):\n",
    "    temp_node = Q_1.get()\n",
    "    print ('---------------')\n",
    "    print (temp_node.get_name())\n",
    "    # update child\n",
    "    print ('***************')\n",
    "    temp_node.set_child(Construct_Node_List(node_dict[temp_node.get_name()].input, temp_node, node_dict))\n",
    "    print ('***************')\n",
    "    # update queue\n",
    "    for elem in temp_node.get_child():\n",
    "        Q_1.put(elem)\n",
    "# root.get_child()[0].get_child()[0].get_Op()\n",
    "def Loop_Multi_Tree(root):\n",
    "    if (len(root.get_child()) == 0):\n",
    "        # which means that it is one leaf node\n",
    "        indegree_node[root] = 0\n",
    "        return\n",
    "    indegree_node[root] = len(root.get_child())\n",
    "    for each_child_node in root.get_child():\n",
    "        print (each_child_node.get_name())\n",
    "        Loop_Multi_Tree(each_child_node)\n",
    "indegree_node = {}\n",
    "Loop_Multi_Tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate the degree of all nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Topo Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_topo = queue.Queue()\n",
    "for each_node in indegree_node:\n",
    "    if indegree_node[each_node] == 0:\n",
    "        q_topo.put(each_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print (q_topo.qsize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construct_topo_json(q_topo, graph, index, data, sess):\n",
    "    while (q_topo.qsize() != 0):\n",
    "        cur_size = q_topo.qsize()\n",
    "        step = \"step\" + str(index)\n",
    "        unit = {}\n",
    "        while cur_size > 0:\n",
    "            single_op = {}\n",
    "            temp_node = q_topo.get()\n",
    "            tensor = graph.get_tensor_by_name(temp_node.get_name()+\":\"+'0')\n",
    "            if temp_node.get_parent() != None:\n",
    "                indegree_node[temp_node.get_parent()] = indegree_node[temp_node.get_parent()] - 1\n",
    "                if (indegree_node[temp_node.get_parent()] == 0):\n",
    "                    q_topo.put(temp_node.get_parent())\n",
    "            if temp_node.get_name().startswith('Variable') and temp_node.get_Op() == 'Identity':\n",
    "                print ('We should get the actual tensor value of the node *** %s ***' % temp_node.get_name())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                tensor_value = tensor.eval(session=sess)\n",
    "                if type(tensor_value) != np.ndarray:\n",
    "                    tensor_value = np.array(tensor_value)\n",
    "                single_op[\"TENSOR_VALUE\"] = tensor_value.tolist()\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape)\n",
    "                single_op[\"STRIDE\"] = None\n",
    "                single_op[\"PADIING\"] = None\n",
    "                single_op[\"INPUT\"] = []\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            elif temp_node.get_Op() == 'Placeholder':\n",
    "                print ('We should fullfill the tensor *** %s *** with input value' % temp_node.get_name())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                single_op[\"TENSOR_VALUE\"] = None\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape)\n",
    "                single_op[\"STRIDE\"] = None\n",
    "                single_op[\"PADIING\"] = None\n",
    "                single_op[\"INPUT\"] = []\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            elif len(temp_node.get_child()) > 0:\n",
    "                # We should note the actual operations\n",
    "                print ('Do %s operation' % temp_node.get_Op())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                single_op[\"TENSOR_VALUE\"] = None\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape) if temp_node.get_Op() == 'Reshape' or temp_node.get_Op() == 'Conv2D' else None\n",
    "                if (temp_node.get_Op() == 'Conv2D'):\n",
    "                    single_op[\"STRIDE\"] = str(tuple([int(elem) for elem in node_dict[temp_node.get_name()].attr['strides'].list.i]))\n",
    "                    single_op[\"PADIING\"] = bytes.decode(node_dict[temp_node.get_name()].attr['padding'].s)\n",
    "                else:\n",
    "                    single_op[\"STRIDE\"] = None\n",
    "                    single_op[\"PADIING\"] = None\n",
    "                input_list = []\n",
    "                for each_input_node in temp_node.get_child():\n",
    "                    print(\"My name is *** %s *** and I am the input of *** %s ***\" % (each_input_node.get_name(), each_input_node.get_parent().get_name()))\n",
    "                    input_list.append(each_input_node.get_name())\n",
    "                single_op[\"INPUT\"] = input_list\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            else:\n",
    "                print ('Do %s operation' % temp_node.get_Op())\n",
    "                single_op[\"TYPE\"] = temp_node.get_name()\n",
    "                single_op[\"TENSOR_VALUE\"] = None\n",
    "                single_op[\"OPERATION\"] = temp_node.get_Op()\n",
    "                single_op[\"SHAPE\"] = str(tensor.shape)\n",
    "                single_op[\"STRIDE\"] = None\n",
    "                single_op[\"PADIING\"] = None\n",
    "                single_op[\"INPUT\"] = []\n",
    "                single_op[\"FATHER\"] = temp_node.get_parent().get_name() if temp_node.get_parent()!= None else None\n",
    "            unit[temp_node.get_name()] = single_op\n",
    "            cur_size = cur_size - 1\n",
    "        index = index + 1\n",
    "        data[step] = unit\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./new_ckpt_dir_3/model-10000\n",
      "We should fullfill the tensor *** x_input *** with input value\n",
      "We should get the actual tensor value of the node *** Variable_1/read ***\n",
      "We should get the actual tensor value of the node *** Variable_2/read ***\n",
      "We should get the actual tensor value of the node *** Variable_3/read ***\n",
      "We should get the actual tensor value of the node *** Variable_4/read ***\n",
      "We should get the actual tensor value of the node *** Variable_5/read ***\n",
      "We should get the actual tensor value of the node *** Variable_6/read ***\n",
      "Do Const operation\n",
      "We should get the actual tensor value of the node *** Variable_7/read ***\n",
      "We should get the actual tensor value of the node *** Variable_8/read ***\n",
      "We should get the actual tensor value of the node *** Variable_9/read ***\n",
      "We should get the actual tensor value of the node *** Variable_10/read ***\n",
      "Do Conv2D operation\n",
      "My name is *** x_input *** and I am the input of *** Conv2D ***\n",
      "My name is *** Variable_1/read *** and I am the input of *** Conv2D ***\n",
      "Do Add operation\n",
      "My name is *** Conv2D *** and I am the input of *** add ***\n",
      "My name is *** Variable_2/read *** and I am the input of *** add ***\n",
      "Do Relu operation\n",
      "My name is *** add *** and I am the input of *** Relu ***\n",
      "Do Conv2D operation\n",
      "My name is *** Relu *** and I am the input of *** Conv2D_1 ***\n",
      "My name is *** Variable_3/read *** and I am the input of *** Conv2D_1 ***\n",
      "Do Add operation\n",
      "My name is *** Conv2D_1 *** and I am the input of *** add_1 ***\n",
      "My name is *** Variable_4/read *** and I am the input of *** add_1 ***\n",
      "Do Relu operation\n",
      "My name is *** add_1 *** and I am the input of *** Relu_1 ***\n",
      "Do Conv2D operation\n",
      "My name is *** Relu_1 *** and I am the input of *** Conv2D_2 ***\n",
      "My name is *** Variable_5/read *** and I am the input of *** Conv2D_2 ***\n",
      "Do Add operation\n",
      "My name is *** Conv2D_2 *** and I am the input of *** add_2 ***\n",
      "My name is *** Variable_6/read *** and I am the input of *** add_2 ***\n",
      "Do Relu operation\n",
      "My name is *** add_2 *** and I am the input of *** Relu_2 ***\n",
      "Do Reshape operation\n",
      "My name is *** Relu_2 *** and I am the input of *** Reshape ***\n",
      "My name is *** Reshape/shape *** and I am the input of *** Reshape ***\n",
      "Do MatMul operation\n",
      "My name is *** Reshape *** and I am the input of *** MatMul ***\n",
      "My name is *** Variable_7/read *** and I am the input of *** MatMul ***\n",
      "Do Add operation\n",
      "My name is *** MatMul *** and I am the input of *** add_3 ***\n",
      "My name is *** Variable_8/read *** and I am the input of *** add_3 ***\n",
      "Do Relu operation\n",
      "My name is *** add_3 *** and I am the input of *** Relu_3 ***\n",
      "Do MatMul operation\n",
      "My name is *** Relu_3 *** and I am the input of *** MatMul_1 ***\n",
      "My name is *** Variable_9/read *** and I am the input of *** MatMul_1 ***\n",
      "Do Add operation\n",
      "My name is *** MatMul_1 *** and I am the input of *** add_4 ***\n",
      "My name is *** Variable_10/read *** and I am the input of *** add_4 ***\n",
      "Do Softmax operation\n",
      "My name is *** add_4 *** and I am the input of *** z_output ***\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./new_ckpt_dir_3/model-10000.meta')\n",
    "    new_saver.restore(sess, './new_ckpt_dir_3/model-10000')\n",
    "    graph = tf.get_default_graph()\n",
    "    from collections import OrderedDict\n",
    "    data = OrderedDict()\n",
    "    index = 0\n",
    "    data = Construct_topo_json(q_topo, graph, index, data, sess)\n",
    "    with open (\"model6.json\", \"w\") as fp:\n",
    "        fp.write(json.dumps(data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
